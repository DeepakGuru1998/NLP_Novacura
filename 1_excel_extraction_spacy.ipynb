{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel Extraction through SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy uses trained neural network pipelines that can be used in regular laptops for different languages. The models are pretrained on various corpora from blogs, text, images and such. So, SpaCy is used to get the understanding of the data much more better than regex methodology. <br>\n",
    "\n",
    "I could have used transformer based models like BeRT within Spacy for better accuracy. But in this use case with given examples, traditional CNN based model like en_core_web_sm was deemed enough with the results it created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import dateparser\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import openpyxl\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_item_codes_by_initials(dfd, product_col='product_name', item_col='item_code'):\n",
    "    \"\"\"\n",
    "    Corrects mismatched item codes by matching product initials with item code prefixes.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with product and item code columns.\n",
    "        product_col (str): Column name containing product names.\n",
    "        item_col (str): Column name containing item codes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected item codes.\n",
    "    \"\"\"\n",
    "\n",
    "    #Extract initials and code prefixes\n",
    "    dfd['Product_Initials'] = dfd[product_col].apply(lambda x: ''.join(word[0].upper() for word in str(x).split()))\n",
    "    dfd['Code_Prefix'] = dfd[item_col].apply(lambda x: str(x).split('-')[0].upper())\n",
    "\n",
    "    #Create possible combinations\n",
    "    combos = dfd[[product_col, 'Product_Initials']].drop_duplicates().merge(\n",
    "        dfd[[item_col, 'Code_Prefix']].drop_duplicates(), how='cross'\n",
    "    )\n",
    "\n",
    "    #Match where initials == code prefix\n",
    "    matched = combos[combos['Product_Initials'] == combos['Code_Prefix']]\n",
    "    match_map = matched.set_index(product_col)[item_col].to_dict()\n",
    "\n",
    "    #Apply corrected item codes\n",
    "    dfd['Corrected_Item_Code'] = dfd[product_col].map(match_map)\n",
    "\n",
    "    #Fall back to original if no match found\n",
    "    dfd['Corrected_Item_Code'] = dfd['Corrected_Item_Code'].fillna(dfd[item_col])\n",
    "\n",
    "    return dfd.drop(['Product_Initials','Code_Prefix','item_code'],axis=1)#[[product_col, item_col, 'Corrected_Item_Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Data saved to 'purchase_orders.excel'.\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Folder with your email .txt files\n",
    "EMAIL_DIR = \"mail/\"\n",
    "records = []\n",
    "\n",
    "def extract_info(text, vendor_name, po_number):\n",
    "    doc = nlp(text)\n",
    "    current_item = defaultdict(list)\n",
    "    current_item[\"vendor\"] = vendor_name\n",
    "    current_item[\"po_number\"] = po_number\n",
    "    # Initialize units with an empty list to avoid the AttributeError\n",
    "    current_item[\"units\"] = []\n",
    "    current_item[\"product_name\"] = []\n",
    "    current_item[\"item_code\"] = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = list(sent)\n",
    "        # Simple way to catch product lines like \"100 units of XYZ (Item Code: XYZ-123)\"\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token.like_num and i + 1 < len(tokens) and \"unit\" in tokens[i+1].text.lower():\n",
    "                # Check if the previous token is also a number (extra/mistake)\n",
    "                if i > 0 and tokens[i-1].like_num:\n",
    "                    # Choose the first number (the one before)\n",
    "                    chosen_num = int(tokens[i-1].text)\n",
    "                else:\n",
    "                    chosen_num = int(token.text)\n",
    "\n",
    "                current_item[\"units\"].append(chosen_num)\n",
    "\n",
    "                # Get product name\n",
    "                name_tokens = []\n",
    "                j = i + 3  # skip \"of\"\n",
    "                while j < len(tokens) and tokens[j].is_alpha:\n",
    "                    name_tokens.append(tokens[j].text.title())\n",
    "                    j += 1\n",
    "                current_item[\"product_name\"].append(\" \".join(name_tokens))\n",
    "\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token.text.lower() == \"code\":\n",
    "                if i + 2 < len(tokens) and tokens[i+1].text in [\":\", \"-\", \"is\"]:\n",
    "                    current_item[\"item_code\"].append(tokens[i+2].text.strip(\").,\"))\n",
    "                elif i + 1 < len(tokens):\n",
    "                    current_item[\"item_code\"].append(tokens[i+1].text.strip(\").,\"))\n",
    "\n",
    "        # Store only complete lines with product name\n",
    "        if current_item[\"product_name\"]:\n",
    "            records.append(current_item.copy())\n",
    "            # Reset to empty lists for next item\n",
    "            current_item[\"product_name\"] = [] \n",
    "            current_item[\"units\"] = []\n",
    "            current_item[\"item_code\"] = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            parsed_date = dateparser.parse(ent.text, settings={'PREFER_DATES_FROM': 'future'})\n",
    "            if parsed_date:\n",
    "                records[-1]['delivery_date'] = parsed_date.date().isoformat()\n",
    "\n",
    "\n",
    "# Go through all .txt files\n",
    "for file in os.listdir(EMAIL_DIR):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filepath = os.path.join(EMAIL_DIR, file)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            # Extract vendor and PO from filename\n",
    "            name = os.path.splitext(file)[0]\n",
    "            if \"_PO_\" in name:\n",
    "                vendor, po = name.split(\"_PO_\")\n",
    "            else:\n",
    "                vendor, po = name, \"\"\n",
    "            extract_info(text, vendor.title(), po)\n",
    "\n",
    "# Save to Excel\n",
    "df = pd.DataFrame(records)\n",
    "df = df.explode(['units', 'product_name', 'item_code'], ignore_index=False)\n",
    "df = correct_item_codes_by_initials(df)\n",
    "df.sort_values(by=['vendor','po_number'],ignore_index=True,inplace=True)\n",
    "df['duplicate'] = df.duplicated(subset=['units', 'product_name', 'Corrected_Item_Code', 'delivery_date', 'vendor'], keep='first').astype(int)\n",
    "df.to_excel(\"purchase_orders.xlsx\", index=False)\n",
    "print(\"Extraction complete. Data saved to 'purchase_orders.excel'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
